{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Csalás felderítés lehetőségei gépi tanuló modellek segítségével - Autoencoder**\n",
    "\n",
    "****\n",
    "\n",
    "### **Könyvtárak, függvények, osztályok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"\\nNum GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saját modulok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "while True:\n",
    "    \n",
    "    if os.path.basename(current_dir) == \"DataScience\":\n",
    "        PATH = os.path.join(current_dir, \"utils\")\n",
    "        break\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "    if parent_dir == current_dir:\n",
    "        raise FileNotFoundError(\"A \\\"DataScience\\\" mappa nem található a mappa-hierarchiában.\")\n",
    "    current_dir = parent_dir\n",
    "    \n",
    "sys.path.append(PATH)\n",
    "import methods\n",
    "import metrics\n",
    "importlib.reload(methods)\n",
    "importlib.reload(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz beolvasása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = methods.read_paysim(get_original_data=False)\n",
    "\n",
    "DATA.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz felosztása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = int(len(DATA)*0.7)\n",
    "VALIDATE_SIZE = 1/4\n",
    "\n",
    "non_fraud, fraud = DATA[ DATA[\"isfraud\"]==0 ], DATA[ DATA[\"isfraud\"]==1 ]\n",
    "non_fraud = non_fraud.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train = non_fraud.iloc[:TRAINING_SIZE].drop(\"isfraud\", axis=1)\n",
    "X_test = pd.concat([non_fraud.iloc[TRAINING_SIZE:], fraud]).sample(frac=1)\n",
    "\n",
    "X_train, X_val = train_test_split(X_train, test_size=VALIDATE_SIZE, random_state=1)\n",
    "X_test, y_test = X_test.drop(\"isfraud\", axis=1), X_test[\"isfraud\"]\n",
    "\n",
    "print(f\"Shapes:\\nNon-fraud: {non_fraud.shape}\\nFraud: {fraud.shape}\")\n",
    "print(f\"Shapes:\\nTrain: {X_train.shape}\\nValidation: {X_val.shape}\\nTest: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Kategorikus oszlopok enkódolása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"transaction_type\", \"sender_receiver_type\"]\n",
    "numerical_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "encoder = CountFrequencyEncoder(\n",
    "    encoding_method=\"frequency\",\n",
    "    variables=categorical_columns\n",
    ")\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "X_val_encoded = encoder.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexek ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( (X_train_encoded.index == X_train.index).all() )\n",
    "print( (X_val_encoded.index == X_val.index).all() )\n",
    "print( (X_test_encoded.index == X_test.index).all() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerikus oszlopok skálázása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_encoded[numerical_columns])\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_encoded.drop(columns=categorical_columns)),\n",
    "    columns=numerical_columns, index=X_train_encoded.index)\n",
    "X_train_transformed = pd.concat([X_train_encoded[categorical_columns], X_train_scaled], axis=1)\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_encoded.drop(columns=categorical_columns)),\n",
    "    columns=numerical_columns, index=X_val_encoded.index)\n",
    "X_val_transformed = pd.concat([X_val_encoded[categorical_columns], X_val_scaled], axis=1)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_encoded.drop(columns=categorical_columns)),\n",
    "    columns=numerical_columns, index=X_test_encoded.index)\n",
    "X_test_transformed = pd.concat([X_test_encoded[categorical_columns], X_test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexek ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train index: {(X_train_transformed.index == X_train.index).all()}\")\n",
    "print(f\"Test index: {(X_test_transformed.index == X_test.index).all()}\")\n",
    "print(f\"Val index: {(X_val_transformed.index == X_val.index).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensorflow és Keras segítségével Autoencoder szerkezetének definiálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION, LATENT_DIMENSION = X_train_transformed.shape[1], 3\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 15\n",
    "\n",
    "print(f\"Input dimension: {INPUT_DIMENSION}\")\n",
    "\n",
    "def build_autoencoder(optimizer_param,\n",
    "                      hidden_activation_function_param,\n",
    "                      output_activation_function_param,\n",
    "                      add_dropout=False,\n",
    "                      dropout_rate=None):\n",
    "    \n",
    "    #encoder\n",
    "    encoder = tf.keras.models.Sequential(name=\"encoder\")\n",
    "    encoder.add( tf.keras.layers.Input(shape=(INPUT_DIMENSION,)) )\n",
    "    encoder.add( tf.keras.layers.Dense(6, activation=hidden_activation_function_param) )\n",
    "    encoder.add( tf.keras.layers.BatchNormalization() )\n",
    "    if add_dropout:\n",
    "        encoder.add( tf.keras.layers.Dropout(dropout_rate) )\n",
    "    bottleneck_layer = tf.keras.layers.Dense(\n",
    "        LATENT_DIMENSION, activation=hidden_activation_function_param, name=\"bottleneck\")\n",
    "    encoder.add(bottleneck_layer)\n",
    "    \n",
    "    #decoder\n",
    "    decoder = tf.keras.models.Sequential(name=\"decoder\")\n",
    "    decoder.add( tf.keras.layers.Input(shape=(LATENT_DIMENSION,)) )\n",
    "    decoder.add( tf.keras.layers.Dense(6, activation=hidden_activation_function_param) )\n",
    "    decoder.add( tf.keras.layers.Dense(INPUT_DIMENSION, activation=output_activation_function_param) )\n",
    "    \n",
    "    # full autoencoder\n",
    "    autoencoder = tf.keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "    autoencoder.compile(\n",
    "        optimizer=optimizer_param,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Autoencoder létrehozása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder, decoder = build_autoencoder(\n",
    "    optimizer_param=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    hidden_activation_function_param=\"relu\",\n",
    "    output_activation_function_param=\"linear\",\n",
    "    add_dropout=False\n",
    ")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Szükséges mappák, callback-ek definiálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_dirname = \"saved_models\"\n",
    "os.makedirs(saved_models_dirname, exist_ok=True)\n",
    "\n",
    "yyyymmddHHMM = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "filename = os.path.join(saved_models_dirname, f\"{yyyymmddHHMM}_batch{BATCH_SIZE}_epochs{EPOCHS}_autoencoder.keras\")\n",
    "\n",
    "autoencoder_result_plots_dir = \"autoencoder_result_plots\"\n",
    "current_autoencoder_dir = os.path.join(autoencoder_result_plots_dir, yyyymmddHHMM)\n",
    "os.makedirs(current_autoencoder_dir, exist_ok=True)\n",
    "\n",
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "cb_save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filename,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "cb = [cb_save_model, cb_early_stopping]\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Autoencoder modell betöltése vagy tanítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = True\n",
    "LOAD_MODEL_FILENAME = \"202503011335_batch256_epochs15_autoencoder.keras\"\n",
    "\n",
    "if LOAD_MODEL == True:\n",
    "    print(f\"Modell betöltés fájlból...\\n{LOAD_MODEL_FILENAME}\")\n",
    "    autoencoder = tf.keras.models.load_model(\"saved_models/\"+LOAD_MODEL_FILENAME)\n",
    "else:\n",
    "    print(\"Modell tanítás megkezdése...\")\n",
    "    history = autoencoder.fit(\n",
    "        X_train_transformed, X_train_transformed,\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks = cb,\n",
    "        validation_data = (X_val_transformed, X_val_transformed)\n",
    "    )\n",
    "    methods.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rekonstrukciók készítése**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predicted = autoencoder.predict(X_test_transformed)\n",
    "X_train_predicted = autoencoder.predict(X_train_transformed)\n",
    "\n",
    "test_mse = metrics.mse(X_test_transformed, X_test_predicted)\n",
    "test_error = pd.DataFrame({ \"Reconstruction_error\": test_mse, \"True_class\": y_test })\n",
    "\n",
    "train_mse = metrics.mse(X_train_transformed, X_train_predicted)\n",
    "train_error = pd.DataFrame({ \"Reconstruction_error\": train_mse, \"True_class\": 0 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák, küszöbértékek kiszámítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(\n",
    "    test_error.True_class, test_error.Reconstruction_error)\n",
    "\n",
    "average_precision = average_precision_score(\n",
    "    test_error.True_class, test_error.Reconstruction_error)\n",
    "\n",
    "f1_score = 2*precision[:-1]*recall[:-1] / (precision[:-1]+recall[:-1])\n",
    "\n",
    "best_index = np.argmax(f1_score)\n",
    "best_threshold = threshold[best_index]\n",
    "\n",
    "best_precision = precision[best_index]\n",
    "best_recall = recall[best_index]\n",
    "max_f1_score = f1_score[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Konfúziós mátrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = (test_error.Reconstruction_error >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_y_test)\n",
    "print(classification_report(y_test, predicted_y_test))\n",
    "confusion_matrix_plot = methods.plot_confusion_matrix(cm)\n",
    "\n",
    "if LOAD_MODEL==False:\n",
    "    confusion_matrix_plot.savefig(os.path.join(current_autoencoder_dir, \"confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Legnagyobb F1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_plot = methods.plot_f1_score(threshold, best_threshold, f1_score, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    f1_score_plot.savefig(os.path.join(current_autoencoder_dir, \"max_f1_score.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PR görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_curve = methods.plot_pr_curve(precision, recall, average_precision, best_precision, best_recall, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    pr_curve.savefig(os.path.join(current_autoencoder_dir, \"PR_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ROC görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_error.True_class, test_error.Reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_auc_curve = methods.plot_roc_curve(fpr, tpr, roc_auc)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    roc_auc_curve.savefig(os.path.join(current_autoencoder_dir, \"ROC_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák kiíratása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.print_metrics(y_test, predicted_y_test,LOAD_MODEL,\n",
    "                      FILENAME=filename,\n",
    "                      LOAD_MODEL_FILENAME=LOAD_MODEL_FILENAME)\n",
    "print(f\"ROC-AUC score: {roc_auc}\")\n",
    "print(f\"Best threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Teszt adathalmaz MSE eloszlása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.kdeplot( test_mse, fill=True, color=\"red\", alpha=1.0 )\n",
    "plt.xlabel(\"MSE (Mean Squared Error)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Test MSE eloszlás\")\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    plt.savefig(os.path.join(current_autoencoder_dir, \"test_mse_distribution.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tanító adathalmaz MSE eloszlása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.kdeplot( train_mse, fill=True, color=\"green\", alpha=1.0 )\n",
    "plt.xlabel(\"MSE (Mean Squared Error)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Train MSE eloszlás\")\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    plt.savefig(os.path.join(current_autoencoder_dir, \"train_mse_distribution.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
