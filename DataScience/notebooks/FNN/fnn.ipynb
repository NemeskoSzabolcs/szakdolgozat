{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Csalás felderítés lehetőségei gépi tanuló modellek segítségével - FNN**\n",
    "\n",
    "****\n",
    "\n",
    "### **Könyvtárak, függvények, osztályok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"\\nNum GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saját modulok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "while True:\n",
    "    \n",
    "    if os.path.basename(current_dir) == \"DataScience\":\n",
    "        PATH = os.path.join(current_dir, \"utils\")\n",
    "        break\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "    if parent_dir == current_dir:\n",
    "        raise FileNotFoundError(\"A \\\"DataScience\\\" mappa nem található a mappa-hierarchiában.\")\n",
    "    \n",
    "    current_dir = parent_dir\n",
    "    \n",
    "sys.path.append(PATH)\n",
    "import methods\n",
    "import metrics\n",
    "importlib.reload(methods)\n",
    "importlib.reload(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz beolvasása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = methods.read_paysim(get_original_data=False)\n",
    "\n",
    "X = DATA.drop('isfraud', axis=1)\n",
    "y = DATA[\"isfraud\"]\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz felosztása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.30\n",
    "VALIDATE_SIZE = 1/4\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=VALIDATE_SIZE, random_state=1, stratify=y_temp)\n",
    "\n",
    "print(f\"Shapes:\\nTrain: {X_train.shape}\\nValidation: {X_val.shape}\\nTest: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Kategorikus oszlopok enkódolása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"transaction_type\", \"sender_receiver_type\"]\n",
    "numerical_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "encoder = CountFrequencyEncoder(\n",
    "    encoding_method=\"frequency\",\n",
    "    variables=categorical_columns\n",
    ")\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "X_val_encoded = encoder.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexek ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( (X_train_encoded.index == X_train.index).all() )\n",
    "print( (X_val_encoded.index == X_val.index).all() )\n",
    "print( (X_test_encoded.index == X_test.index).all() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerikus oszlopok skálázása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train_encoded[numerical_columns])\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_train_encoded[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_train_encoded.index)\n",
    "X_train_transformed = pd.concat([X_train_encoded[categorical_columns], X_train_scaled], axis=1)\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_val_encoded[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_val_encoded.index)\n",
    "X_val_transformed = pd.concat([X_val_encoded[categorical_columns], X_val_scaled], axis=1)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_test_encoded[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_test_encoded.index)\n",
    "X_test_transformed = pd.concat([X_test_encoded[categorical_columns], X_test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexek ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train index: {(X_train_transformed.index == X_train.index).all()}\")\n",
    "print(f\"Test index: {(X_test_transformed.index == X_test.index).all()}\")\n",
    "print(f\"Val index: {(X_val_transformed.index == X_val.index).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mintasúlyok létrehozása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ha y_train = 1, akkor súly=10, egyébként súly=1\n",
    "\n",
    "sample_weights = np.where(y_train==1, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensorflow és Keras segítségével Autoencoder szerkezetének definiálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION, OUTPUT_DIMENSION = X_train_transformed.shape[1], 1\n",
    "NEURONS = 6\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 15\n",
    "\n",
    "def build_fnn(num_layers,\n",
    "              optimizer_param,\n",
    "              hidden_activation_function_param,\n",
    "              output_activation_function_param,\n",
    "              add_dropout=False,\n",
    "              dropout_rate=None):\n",
    "    \n",
    "    fnn = tf.keras.models.Sequential()\n",
    "    fnn.add( tf.keras.layers.Input(shape=(INPUT_DIMENSION,)) )\n",
    "    for _ in range(num_layers - 1):\n",
    "        fnn.add(tf.keras.layers.Dense(NEURONS, activation=hidden_activation_function_param))\n",
    "        fnn.add( tf.keras.layers.BatchNormalization() )\n",
    "        if add_dropout:\n",
    "            fnn.add( tf.keras.layers.Dropout(dropout_rate) )\n",
    "            \n",
    "    fnn.add(tf.keras.layers.Dense(NEURONS, activation=hidden_activation_function_param))\n",
    "    fnn.add( tf.keras.layers.BatchNormalization() )\n",
    "    fnn.add(tf.keras.layers.Dense(OUTPUT_DIMENSION, activation=output_activation_function_param))\n",
    "\n",
    "    fnn.compile(\n",
    "        optimizer=optimizer_param,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"auc\", \"precision\", \"recall\"]\n",
    "    )\n",
    "\n",
    "    return fnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FNN létrehozása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn = build_fnn(\n",
    "    num_layers=2,\n",
    "    optimizer_param=tf.keras.optimizers.AdamW(learning_rate = 0.00001),\n",
    "    hidden_activation_function_param=\"relu\",\n",
    "    output_activation_function_param=\"sigmoid\",\n",
    "    add_dropout=False\n",
    ")\n",
    "fnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Szükséges mappák, callback-ek definiálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_dirname = \"saved_models\"\n",
    "os.makedirs(saved_models_dirname, exist_ok=True)\n",
    "\n",
    "yyyymmddHHMM = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "filename = os.path.join(saved_models_dirname, f\"{yyyymmddHHMM}_batch{BATCH_SIZE}_epochs{EPOCHS}_fnn.keras\")\n",
    "\n",
    "fnn_result_plots_dir = \"fnn_result_plots\"\n",
    "current_fnn_dir = os.path.join(fnn_result_plots_dir, yyyymmddHHMM)\n",
    "os.makedirs(current_fnn_dir, exist_ok=True)\n",
    "\n",
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    patience=2\n",
    ")\n",
    "cb_save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filename,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "cb = [cb_save_model, cb_early_stopping]\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FNN modell betöltése vagy tanítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = True\n",
    "LOAD_MODEL_FILENAME = \"202504241513_batch256_epochs15_fnn.keras\"\n",
    "\n",
    "if LOAD_MODEL == True:\n",
    "    print(f\"Modell betöltés fájlból...\\n{LOAD_MODEL_FILENAME}\")\n",
    "    fnn = tf.keras.models.load_model(\"saved_models/\"+LOAD_MODEL_FILENAME)\n",
    "else:\n",
    "    print(\"Modell tanítás megkezdése...\")\n",
    "    history = fnn.fit(\n",
    "        X_train_transformed, y_train,\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks = cb,\n",
    "        validation_data = (X_val_transformed, y_val),\n",
    "        sample_weight = sample_weights\n",
    "    )\n",
    "    model_loss = methods.plot_history(history)\n",
    "    model_loss.savefig(os.path.join(current_fnn_dir, \"model_loss.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Előrejelzések készítése**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = fnn.predict(X_test_transformed)\n",
    "y_val_predicted = fnn.predict(X_val_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák, küszöbértékek kiszámítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_val, y_val_predicted)\n",
    "f1_score = 2*precision[:-1]*recall[:-1] / (precision[:-1]+recall[:-1])\n",
    "average_precision = average_precision_score(y_test, y_test_predicted)\n",
    "\n",
    "best_index = np.argmax(f1_score)\n",
    "best_threshold = threshold[best_index]\n",
    "\n",
    "best_precision = precision[best_index]\n",
    "best_recall = recall[best_index]\n",
    "max_f1_score = f1_score[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ROC görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_auc_curve = methods.plot_roc_curve(fpr, tpr, roc_auc)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    roc_auc_curve.savefig(os.path.join(current_fnn_dir, \"ROC_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Osztályokhoz rendelés, és $classification\\_report$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_best_threshold = (y_test_predicted >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Test:\\n{classification_report(y_test, y_test_predicted_best_threshold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák kiíratása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.print_metrics(y_test, y_test_predicted_best_threshold,LOAD_MODEL,\n",
    "                      FILENAME=filename,\n",
    "                      LOAD_MODEL_FILENAME=LOAD_MODEL_FILENAME)\n",
    "print(f\"ROC-AUC score: {roc_auc}\")\n",
    "print(f\"Best threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Konfúziós mátrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_predicted_best_threshold)\n",
    "\n",
    "confusion_matrix_best_threshold = methods.plot_confusion_matrix(cm)\n",
    "if LOAD_MODEL==False:\n",
    "    confusion_matrix_best_threshold.savefig(os.path.join(current_fnn_dir, \"confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Legnagyobb F1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_plot = methods.plot_f1_score(threshold, best_threshold, f1_score, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    f1_score_plot.savefig(os.path.join(current_fnn_dir, \"max_f1_score.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PR görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_curve = methods.plot_pr_curve(precision, recall, average_precision, best_precision, best_recall, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    pr_curve.savefig(os.path.join(current_fnn_dir, \"PR_curve.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
