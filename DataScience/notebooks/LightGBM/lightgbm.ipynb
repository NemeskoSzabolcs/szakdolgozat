{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Csalás felderítés lehetőségei gépi tanuló modellek segítségével - LightGBM**\n",
    "\n",
    "****\n",
    "\n",
    "### **Könyvtárak, függvények, osztályok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "import lightgbm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saját modulok importálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "while True:\n",
    "    \n",
    "    if os.path.basename(current_dir) == \"DataScience\":\n",
    "        PATH = os.path.join(current_dir, \"utils\")\n",
    "        break\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "    if parent_dir == current_dir:\n",
    "        raise FileNotFoundError(\"A \\\"DataScience\\\" mappa nem található a mappa-hierarchiában.\")\n",
    "    \n",
    "    current_dir = parent_dir\n",
    "    \n",
    "sys.path.append(PATH)\n",
    "import methods\n",
    "import metrics\n",
    "importlib.reload(methods)\n",
    "importlib.reload(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz beolvasása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = methods.read_paysim(get_original_data=False)\n",
    "\n",
    "X = DATA.drop('isfraud', axis=1)\n",
    "y = DATA[\"isfraud\"]\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adathalmaz felosztása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.30\n",
    "VALIDATE_SIZE = 1/4\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=VALIDATE_SIZE, random_state=1, stratify=y_temp)\n",
    "print(f\"Shapes:\\nTrain: {X_train.shape}\\nValidation: {X_val.shape}\\nTest: {X_test.shape}\")\n",
    "\n",
    "del X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerikus oszlopok skálázása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"transaction_type\", \"sender_receiver_type\"]\n",
    "numerical_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train[numerical_columns])\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_train[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_train.index)\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_val[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_val.index)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    standard_scaler.transform(X_test[numerical_columns]),\n",
    "    columns=numerical_columns, index=X_test.index)\n",
    "\n",
    "X_train_transformed = pd.concat([X_train[categorical_columns], X_train_scaled], axis=1)\n",
    "X_val_transformed = pd.concat([X_val[categorical_columns], X_val_scaled], axis=1)\n",
    "X_test_transformed = pd.concat([X_test[categorical_columns], X_test_scaled], axis=1)\n",
    "\n",
    "\n",
    "del X_train_scaled, X_val_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Kategorikus oszlopok $category$ típussá konvertálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    X_train_transformed[col] = X_train_transformed[col].astype(\"category\")\n",
    "    X_test_transformed[col] = X_test_transformed[col].astype(\"category\")\n",
    "    X_val_transformed[col] = X_val_transformed[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexek ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train index: {(X_train_transformed.index == X_train.index).all()}\")\n",
    "print(f\"Test index: {(X_test_transformed.index == X_test.index).all()}\")\n",
    "print(f\"Val index: {(X_val_transformed.index == X_val.index).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Szükséges mappák létrehozása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_dirname = \"saved_models\"\n",
    "os.makedirs(saved_models_dirname, exist_ok=True)\n",
    "\n",
    "yyyymmddHHMM = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "filename = os.path.join(saved_models_dirname, f\"{yyyymmddHHMM}_lightgbm.pkl\")\n",
    "\n",
    "lightgbm_result_plots_dir = \"lightgbm_result_plots\"\n",
    "current_lightgbm_dir = os.path.join(lightgbm_result_plots_dir, yyyymmddHHMM)\n",
    "os.makedirs(current_lightgbm_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV és LightGBM modell definiálása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = True\n",
    "LOAD_MODEL_FILENAME = \"202504162048_lightgbm.pkl\"\n",
    "GRIDSEARCH = False\n",
    "\n",
    "#* Mindenképpen meg lesz adva a modell definiálásánál\n",
    "lgbm_fix_params = {\n",
    "    \"random_state\": 1, \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "}\n",
    "lgbm_params = {\n",
    "    \"learning_rate\": 0.001, \"colsample_bytree\": 0.7,\n",
    "    \"subsample\": 0.7, \"n_estimators\": 100,\n",
    "    \"num_leaves\": 16, \"max_depth\": 4,\n",
    "    \"reg_alpha\": 0.8, \"reg_lambda\": 0.8,\n",
    "}\n",
    "evals = {}\n",
    "\n",
    "#* Modell betöltése\n",
    "if LOAD_MODEL == True:\n",
    "    print(f\"Modell betöltés fájlból...\\n{LOAD_MODEL_FILENAME}\")\n",
    "    lgbm = joblib.load(f\"saved_models/{LOAD_MODEL_FILENAME}\")\n",
    "    print(\"Modell betöltve\")\n",
    "\n",
    "#* GridSearchCV / Előre definiált hiperparaméterek alapján modell létrehozás\n",
    "else:\n",
    "    \n",
    "    if GRIDSEARCH==True:\n",
    "        \n",
    "        gridsearch_params = {}\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=lightgbm.LGBMClassifier(**lgbm_fix_params, **lgbm_params),\n",
    "            param_grid=gridsearch_params,\n",
    "            cv=3,\n",
    "            scoring=[\"precision\", \"recall\", \"f1\", \"roc_auc\"],\n",
    "            refit=\"f1\",\n",
    "            return_train_score=True,\n",
    "            n_jobs=6\n",
    "        )\n",
    "        \n",
    "        grid_search_start = time.time()\n",
    "        print(f\"Info: GridSearchCV elkezdése a következő hiperparaméterekkel:\\n{gridsearch_params}\")\n",
    "        grid_search.fit(X_train_transformed, y_train)\n",
    "        print(\"Info: GridSearchCV befejezve\")\n",
    "        grid_search_end = time.time()\n",
    "        print(f\"Eltelt idő: {grid_search_end - grid_search_start} s\")\n",
    "                \n",
    "        print(f\"\\nInfo: GridSearch legjobb hiperparaméterek kombinációk:\\n{grid_search.best_params_}\")\n",
    "        print(f\"Alap hiperparaméterek:\\n{lgbm_fix_params}\")\n",
    "        \n",
    "        lgbm_params = {**lgbm_params, **grid_search.best_params_}\n",
    "        \n",
    "    print(f\"Info: LightGBM modell létrehozása a következő hiperparaméterekkel\\n{lgbm_params}\")\n",
    "    \n",
    "    lgbm = lightgbm.LGBMClassifier(\n",
    "        **lgbm_fix_params,\n",
    "        **lgbm_params\n",
    "    )\n",
    "        \n",
    "    print(f\"\\nTeljes hiperparaméter lista:\")\n",
    "    for i,j in lgbm.get_params().items():\n",
    "        print(f\"{i}: {j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LightGBM modell betöltése vagy tanítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_fit_params = {\n",
    "    \"eval_set\": [(X_train_transformed, y_train), (X_val_transformed, y_val)],\n",
    "    \"eval_metric\": \"binary_logloss\",\n",
    "    \"callbacks\": [lightgbm.early_stopping(stopping_rounds=10, verbose=True),\n",
    "                  lightgbm.record_evaluation(evals)],\n",
    "    \"categorical_feature\": categorical_columns\n",
    "}\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    print(\"Modell tanítás megkezdése...\")\n",
    "    lgbm.fit(\n",
    "        X_train_transformed, y_train,\n",
    "        **lgbm_fit_params\n",
    "    )\n",
    "    print(f\"Modell mentése a következő elérési útra: {filename}\")\n",
    "    joblib.dump(lgbm, filename)\n",
    "else:\n",
    "    print(\"Info: Beolvasott modell nem kerül újra tanításra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrika változása tanítás alatt (tanulási görbe)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL == False:\n",
    "    lightgbm.plot_metric(evals)\n",
    "    plt.savefig(os.path.join(current_lightgbm_dir, \"metric_during_training.png\"))\n",
    "else:\n",
    "    print(\"Info: Modell betöltésnél nem ábrázolható a tanítás közbeni metrika változása.\\nA következő képen lehet megtekinteni: \\\"metric_during_training.png\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm.plot_importance(lgbm)\n",
    "plt.tight_layout()\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    plt.savefig(os.path.join(current_lightgbm_dir, \"feature_importance.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximális fa mélység lekérése (optimalizáláshoz kell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_info = lgbm.booster_.dump_model()[\"tree_info\"]\n",
    "max_depth = methods.lgbm_get_max_tree_depth(tree_info)\n",
    "print(f\"Maximális fa mélység: {max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Előrejelzések készítése**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predicted_proba = lgbm.predict_proba(X_val_transformed)[:, 1]\n",
    "X_test_predicted_proba = lgbm.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák, küszöbértékek kiszámítása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_val, X_val_predicted_proba)\n",
    "f1_score = 2*precision[:-1]*recall[:-1] / (precision[:-1]+recall[:-1])\n",
    "average_precision = average_precision_score(y_test, X_test_predicted_proba)\n",
    "\n",
    "best_index = np.argmax(f1_score)\n",
    "best_threshold = threshold[best_index]\n",
    "\n",
    "best_precision = precision[best_index]\n",
    "best_recall = recall[best_index]\n",
    "max_f1_score = f1_score[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ROC görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, X_test_predicted_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_auc_curve = methods.plot_roc_curve(fpr, tpr, roc_auc)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    roc_auc_curve.savefig(os.path.join(current_lightgbm_dir, \"ROC_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Osztályokhoz rendelés, és $classification\\_report$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_best_threshold = (X_test_predicted_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Test:\\n{classification_report(y_test, y_test_predicted_best_threshold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrikák kiíratása**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.print_metrics(y_test, y_test_predicted_best_threshold, LOAD_MODEL,\n",
    "                      FILENAME=filename,\n",
    "                      LOAD_MODEL_FILENAME=LOAD_MODEL_FILENAME)\n",
    "print(f\"ROC-AUC score: {roc_auc}\")\n",
    "print(f\"Best threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Konfúziós mátrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_predicted_best_threshold)\n",
    "\n",
    "confusion_matrix_best_threshold = methods.plot_confusion_matrix(cm)\n",
    "if LOAD_MODEL==False:\n",
    "    confusion_matrix_best_threshold.savefig(os.path.join(current_lightgbm_dir, \"confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Legnagyobb F1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_plot = methods.plot_f1_score(threshold, best_threshold, f1_score, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    f1_score_plot.savefig(os.path.join(current_lightgbm_dir, \"max_f1_score.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PR görbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_curve = methods.plot_pr_curve(precision, recall, average_precision, best_precision, best_recall, max_f1_score)\n",
    "\n",
    "if LOAD_MODEL == False:\n",
    "    pr_curve.savefig(os.path.join(current_lightgbm_dir, \"PR_curve.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
